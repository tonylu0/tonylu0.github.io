{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to my Website This is my personal website to document my projects. This website documents the code for the projects. This website will also include text tutorials for projects as well as video guides in the future. Currently planned tutorials include using FastAI on VastAI and modifying a docker image to save bandwidth. Resources Used FastAI is a great library to get quickly started with machine learning projects. However, this library requires the use of an Nvidia GPU. For learners that do not have an Nvidia GPU, resources such as Paperspace and VastAI can provide remote GPU resources to allow anyone to use FastAI with just a browser. Recommendations for Cloud GPU compute providers How to use FastAI on VastAI Remote compute services do not require the user to install everything manually. Rather, they provide the option of using docker images. Docker images are portable enviornments with everything set up for the user. Thus, they do not need to worry about installing dependencies for programs and can get straight to work.","title":"Home"},{"location":"#welcome-to-my-website","text":"This is my personal website to document my projects. This website documents the code for the projects. This website will also include text tutorials for projects as well as video guides in the future. Currently planned tutorials include using FastAI on VastAI and modifying a docker image to save bandwidth.","title":"Welcome to my Website"},{"location":"#resources-used","text":"FastAI is a great library to get quickly started with machine learning projects. However, this library requires the use of an Nvidia GPU. For learners that do not have an Nvidia GPU, resources such as Paperspace and VastAI can provide remote GPU resources to allow anyone to use FastAI with just a browser. Recommendations for Cloud GPU compute providers How to use FastAI on VastAI Remote compute services do not require the user to install everything manually. Rather, they provide the option of using docker images. Docker images are portable enviornments with everything set up for the user. Thus, they do not need to worry about installing dependencies for programs and can get straight to work.","title":"Resources Used"},{"location":"about/","text":"About me Objective I am currently seeking a full time position in Software Development. I bring experience from personal projects and research to support the development of technical projects. Education Undergraduate at The Ohio State University Graduated May 2021 BS / Computer Engineering GPA: 3.69 Work Experience Computer Architecture Research Lab Assistant - Ohio State University November 2019 - May 2020 Developed novel security implementations using Hardware Accelerated Stochastic Inference (HASI) for machine learning accelerators. Collaborative development of defenses against adversarial attacks using FPGAs. Course Assistant - University of Illinois at Urbana-Champaign January 2018 - May 2018 Mentored students by holding office hours in the Introduction to Computer Science class. Educated students on problem solving techniques. Personal Projects Anime Face Generator Used Stylegan2 on a custom set of anime faces to generate similar fake anime faces. Created a python script to generate a folder of cropped anime faces from a folder images. Created a python script to preprocess images to meet Stylegan2 requirements and to resize images to a custom size. Created a custom docker image with Stylegan2 and the training dataset to enable training on powerful remote machines in VastAI to reduce bandwidth cost. Using FastAI on VastAI tutorial Created text and video tutorial on how to use FastAI on VastAI Online anime recognizer Used FastAI to deploy a machine learning model online using mybinder to recognize anime faces. Created GUI to select images. Technical Skills Languages and Development Tools Python, Java, C++, Verilog Visual Studio Code, Eclipse, Xilinx Vivado Markdown","title":"About Me"},{"location":"about/#about-me","text":"","title":"About me"},{"location":"about/#objective","text":"I am currently seeking a full time position in Software Development. I bring experience from personal projects and research to support the development of technical projects.","title":"Objective"},{"location":"about/#education","text":"Undergraduate at The Ohio State University Graduated May 2021 BS / Computer Engineering GPA: 3.69","title":"Education"},{"location":"about/#work-experience","text":"Computer Architecture Research Lab Assistant - Ohio State University November 2019 - May 2020 Developed novel security implementations using Hardware Accelerated Stochastic Inference (HASI) for machine learning accelerators. Collaborative development of defenses against adversarial attacks using FPGAs. Course Assistant - University of Illinois at Urbana-Champaign January 2018 - May 2018 Mentored students by holding office hours in the Introduction to Computer Science class. Educated students on problem solving techniques.","title":"Work Experience"},{"location":"about/#personal-projects","text":"Anime Face Generator Used Stylegan2 on a custom set of anime faces to generate similar fake anime faces. Created a python script to generate a folder of cropped anime faces from a folder images. Created a python script to preprocess images to meet Stylegan2 requirements and to resize images to a custom size. Created a custom docker image with Stylegan2 and the training dataset to enable training on powerful remote machines in VastAI to reduce bandwidth cost. Using FastAI on VastAI tutorial Created text and video tutorial on how to use FastAI on VastAI Online anime recognizer Used FastAI to deploy a machine learning model online using mybinder to recognize anime faces. Created GUI to select images.","title":"Personal Projects"},{"location":"about/#technical-skills","text":"Languages and Development Tools Python, Java, C++, Verilog Visual Studio Code, Eclipse, Xilinx Vivado Markdown","title":"Technical Skills"},{"location":"recommendations/","text":"Recommended Cloud GPU Resources Free Options Paperspace Uses Jupyter Notebook by default. Free Nvidia Quadro M4000 8GB instances with 2.57 FP32 TFLOPS. Free instances allow usage of up to 6 hours at a time. 5GB of persistant storage that all notebooks can access. No limit to how many times you can use free instances. Free instaces first come first served and are hard to get before and after work hours when people have free time to work on side projects. Can provide custom docker image. Google Colab Uses Google's version of Jupyter Notebooks. Functionality is similar with a few keybinds changed. Free Nvidia Tesla K80 12GB with 4.1 FP32 TFLOPS, Nvidia Tesla T4 16GB with 8.14 FP32 TFLOPS, Nvidia Tesla P4 8GB with 5.7 FP32 TFLOPS, Nvidia Tesla P100 16GB with 9.5 FP32 TFLOPS provided arbitrarily (you can't choose what you get). Note that the Nvidia T4 and P100 have increased FP16 compute to increase computation. Collab allows usage of up to 12 hours at a time. Uses Google Drive storage. Limits based on recent usage with the priority of GPUs given to users with the least amount of recent usage. Instances available based on past usage. Limited to Colab scripts and can not use custom docker images. Paid Options Paperspace $8/month - $39/month Same as above except Unlocks more free tiers with Nvidia Quadro P5000 16GB with 8.9 FP32 TFLOPS and RTX4000 8GB with 7.1 FP32 TFLOPS Higher tier membership unlocks more free tiers with Nvidia RTX A4000 16GB with 19.2 FP32 TFLOPS and Nvidia A100 40GB with 19.5 FP32 TFLOPS Note that the Nvidia RTX4000 and A100 have increased FP16 compute to increase computation. Free P5000 instances are almost always available (basically unlimited P5000 use). Google Colab $10/month Same as above except Allows for more usage, but still limited VastAI $5 deposit minimum, price depends on rental How to use FastAI on VastAI Uses docker images, can use custom docker image. Instead of using servers which are not allowed to use consumer GPUs, VastAI uses decentralized compute where anyone can rent out their GPUs. This allows for much cheaper prices as consumer GPUs have a much better price to performance ratio. However, you can not work with sensitive data as it is hosted anyones computers. Examples include RTX 3090 24GB with 35.6 FP32 TFLOPS for $0.50 an hour, GTX 1080 Ti 11GB with 11.3 FP32 TFLOPS for $0.20 an hour, RTX A6000 48GB with 40 FP32 TFLOPS for $0.80 an hour. Allows for interruptable instances that cost a fraction of the previous prices if your work can be periodically backed up online and automatically resumed.","title":"Cloud GPU Recommendations"},{"location":"recommendations/#recommended-cloud-gpu-resources","text":"","title":"Recommended Cloud GPU Resources"},{"location":"recommendations/#free-options","text":"Paperspace Uses Jupyter Notebook by default. Free Nvidia Quadro M4000 8GB instances with 2.57 FP32 TFLOPS. Free instances allow usage of up to 6 hours at a time. 5GB of persistant storage that all notebooks can access. No limit to how many times you can use free instances. Free instaces first come first served and are hard to get before and after work hours when people have free time to work on side projects. Can provide custom docker image. Google Colab Uses Google's version of Jupyter Notebooks. Functionality is similar with a few keybinds changed. Free Nvidia Tesla K80 12GB with 4.1 FP32 TFLOPS, Nvidia Tesla T4 16GB with 8.14 FP32 TFLOPS, Nvidia Tesla P4 8GB with 5.7 FP32 TFLOPS, Nvidia Tesla P100 16GB with 9.5 FP32 TFLOPS provided arbitrarily (you can't choose what you get). Note that the Nvidia T4 and P100 have increased FP16 compute to increase computation. Collab allows usage of up to 12 hours at a time. Uses Google Drive storage. Limits based on recent usage with the priority of GPUs given to users with the least amount of recent usage. Instances available based on past usage. Limited to Colab scripts and can not use custom docker images.","title":"Free Options"},{"location":"recommendations/#paid-options","text":"Paperspace $8/month - $39/month Same as above except Unlocks more free tiers with Nvidia Quadro P5000 16GB with 8.9 FP32 TFLOPS and RTX4000 8GB with 7.1 FP32 TFLOPS Higher tier membership unlocks more free tiers with Nvidia RTX A4000 16GB with 19.2 FP32 TFLOPS and Nvidia A100 40GB with 19.5 FP32 TFLOPS Note that the Nvidia RTX4000 and A100 have increased FP16 compute to increase computation. Free P5000 instances are almost always available (basically unlimited P5000 use). Google Colab $10/month Same as above except Allows for more usage, but still limited VastAI $5 deposit minimum, price depends on rental How to use FastAI on VastAI Uses docker images, can use custom docker image. Instead of using servers which are not allowed to use consumer GPUs, VastAI uses decentralized compute where anyone can rent out their GPUs. This allows for much cheaper prices as consumer GPUs have a much better price to performance ratio. However, you can not work with sensitive data as it is hosted anyones computers. Examples include RTX 3090 24GB with 35.6 FP32 TFLOPS for $0.50 an hour, GTX 1080 Ti 11GB with 11.3 FP32 TFLOPS for $0.20 an hour, RTX A6000 48GB with 40 FP32 TFLOPS for $0.80 an hour. Allows for interruptable instances that cost a fraction of the previous prices if your work can be periodically backed up online and automatically resumed.","title":"Paid Options"},{"location":"projects/animefacecrop/","text":"Anime Face Cropper Link to Github: https://github.com/tonylu0/lbpcascade_animeface Introduction This step of the anime face generator includes downloading the custom set of anime images as well as cropping the faces from the images. Downloading custom images First, you will need a custom folder of images. For downloading anime photos, I used Grabber , which can be used to download images from image boards. Once you have a folder of images, go through the folder manually to ensure that everything in the folder is relevant to the data you want to use. This is the second most time consuming step, depending on how many training images you want to use. Using the anime face cropper After you a folder of images you want to use, first make a copy of the folder. This will be the folder that we will feed into the anime face cropper and irrelevant images will be deleted. After you have made a copy of the image folder, clone the Github repository. This includes the model that recognizes anime faces as well as the code to automatically crop images and crop folders. Create a new python file or python notebook and copy and paste the contents of the README into it. The portion of the code is copied below for your convenience. import cv2 import sys import os.path def detect ( filename , cascade_file = \"lbpcascade_animeface.xml\" ): if not os . path . isfile ( cascade_file ): raise RuntimeError ( \" %s : not found\" % cascade_file ) cascade = cv2 . CascadeClassifier ( cascade_file ) image = cv2 . imread ( filename , cv2 . IMREAD_COLOR ) gray = cv2 . cvtColor ( image , cv2 . COLOR_BGR2GRAY ) gray = cv2 . equalizeHist ( gray ) faces = cascade . detectMultiScale ( gray , # detector options scaleFactor = 1.1 , minNeighbors = 5 , minSize = ( 24 , 24 )) flag = 0 count = 1 for ( x , y , w , h ) in faces : crop_img = image [ y : y + h , x : x + w ] if len ( faces ) > 1 : base = os . path . splitext ( filename )[ 0 ] extension = os . path . splitext ( filename )[ 1 ] newfilename = base + str ( count ) + extension cv2 . imwrite ( newfilename , crop_img ) else : cv2 . imwrite ( filename , crop_img ) flag = 1 count += 1 if len ( faces ) > 1 : try : os . remove ( filename ) except : pass if ( flag == 0 ) : try : os . remove ( filename ) except : pass # To produce red bounding box on faces # for (x, y, w, h) in faces: # cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2) # cv2.imshow(\"AnimeFaceDetect\", image) #Opens window to show image # cv2.waitKey(0) # cv2.imwrite(\"out.png\", image) The code above has commented out the portion for the creation of the red bounding boxes since it is not needed. In order to apply this script to an entire folder, the next code snippet will be used. import cv2 import sys import os.path directory = 'Hibiki_crop' for filename in os . listdir ( directory ): file = os . path . join ( directory , filename ) detect ( file ) Place the copy of the folder that contains the images that you want to crop in the same directory as the lbpcascade_animeface file and python script. Replace the directory Hibiki_crop with your own folder name. After you run this script, it will go through the images in the folder and crop out the faces and deleting everything else. This folder will only contain cropped faces. Now you will have a folder of cropped anime faces to use as your custom data.","title":"Anime Face Cropper"},{"location":"projects/animefacecrop/#anime-face-cropper","text":"Link to Github: https://github.com/tonylu0/lbpcascade_animeface","title":"Anime Face Cropper"},{"location":"projects/animefacecrop/#introduction","text":"This step of the anime face generator includes downloading the custom set of anime images as well as cropping the faces from the images.","title":"Introduction"},{"location":"projects/animefacecrop/#downloading-custom-images","text":"First, you will need a custom folder of images. For downloading anime photos, I used Grabber , which can be used to download images from image boards. Once you have a folder of images, go through the folder manually to ensure that everything in the folder is relevant to the data you want to use. This is the second most time consuming step, depending on how many training images you want to use.","title":"Downloading custom images"},{"location":"projects/animefacecrop/#using-the-anime-face-cropper","text":"After you a folder of images you want to use, first make a copy of the folder. This will be the folder that we will feed into the anime face cropper and irrelevant images will be deleted. After you have made a copy of the image folder, clone the Github repository. This includes the model that recognizes anime faces as well as the code to automatically crop images and crop folders. Create a new python file or python notebook and copy and paste the contents of the README into it. The portion of the code is copied below for your convenience. import cv2 import sys import os.path def detect ( filename , cascade_file = \"lbpcascade_animeface.xml\" ): if not os . path . isfile ( cascade_file ): raise RuntimeError ( \" %s : not found\" % cascade_file ) cascade = cv2 . CascadeClassifier ( cascade_file ) image = cv2 . imread ( filename , cv2 . IMREAD_COLOR ) gray = cv2 . cvtColor ( image , cv2 . COLOR_BGR2GRAY ) gray = cv2 . equalizeHist ( gray ) faces = cascade . detectMultiScale ( gray , # detector options scaleFactor = 1.1 , minNeighbors = 5 , minSize = ( 24 , 24 )) flag = 0 count = 1 for ( x , y , w , h ) in faces : crop_img = image [ y : y + h , x : x + w ] if len ( faces ) > 1 : base = os . path . splitext ( filename )[ 0 ] extension = os . path . splitext ( filename )[ 1 ] newfilename = base + str ( count ) + extension cv2 . imwrite ( newfilename , crop_img ) else : cv2 . imwrite ( filename , crop_img ) flag = 1 count += 1 if len ( faces ) > 1 : try : os . remove ( filename ) except : pass if ( flag == 0 ) : try : os . remove ( filename ) except : pass # To produce red bounding box on faces # for (x, y, w, h) in faces: # cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2) # cv2.imshow(\"AnimeFaceDetect\", image) #Opens window to show image # cv2.waitKey(0) # cv2.imwrite(\"out.png\", image) The code above has commented out the portion for the creation of the red bounding boxes since it is not needed. In order to apply this script to an entire folder, the next code snippet will be used. import cv2 import sys import os.path directory = 'Hibiki_crop' for filename in os . listdir ( directory ): file = os . path . join ( directory , filename ) detect ( file ) Place the copy of the folder that contains the images that you want to crop in the same directory as the lbpcascade_animeface file and python script. Replace the directory Hibiki_crop with your own folder name. After you run this script, it will go through the images in the folder and crop out the faces and deleting everything else. This folder will only contain cropped faces. Now you will have a folder of cropped anime faces to use as your custom data.","title":"Using the anime face cropper"},{"location":"projects/animefacegenerator/","text":"Anime face generator Introduction The goal for this project is to generate new images based on supplied images. In this case, I wished to generate more anime faces based on the supplied anime face data. In order to do so, I used Stylegan2-ada. Stylegan2-ada is Nvidia's GAN (Generative Adversarial Network). Anime face cropper In order to limit the scope of the image generation, we need to first crop the anime faces from the images. While using the entire image to generate more fake images is possible, it is a lot more complicated computation wise, and does not transfer well when using the transfer learning technique. Image preprocessor After obtaining a set of training images, the images then need to be transformed into an appropriate data format so that the GAN model will use. The image preprocessing step will crop the images into square images, ensure that the images are in the RGB colorspace, and make sure the file formats are correct. Custom docker image for GAN training After the training data is finished with preprocessing, we need to convert it to a format that the GAN will accept. In the custom docker image we will use a script provided by Nvidia called dataset_tool.py that will turn the images into TFRecords, which can be fed into the GAN. Training on VastAI In this step, we will then load the docker image with the TFRecords data into VastAI, which allows us to use custom docker images on rental GPU servers. This allows us to use multiple GPUs at once, greatly decreasing the time spent training. After we are done training, the model can be downloaded from the results folder to produce fake images. Sample fake images will also be in the results folder, as well as model checkpoints and sample images at the checkpoints. Full tutorial on how to use custom images in stylegan2-ada A text and video tutorial will be made on how to follow along in using custom images to create fake images using stylegan2-ada. The text tutorial will be in the following pages in the Anime Face Generator directory. Anime Face Cropper - Finished Image Preprocessor - In progress Custom docker image for GAN training - In progress","title":"Project Home"},{"location":"projects/animefacegenerator/#anime-face-generator","text":"","title":"Anime face generator"},{"location":"projects/animefacegenerator/#introduction","text":"The goal for this project is to generate new images based on supplied images. In this case, I wished to generate more anime faces based on the supplied anime face data. In order to do so, I used Stylegan2-ada. Stylegan2-ada is Nvidia's GAN (Generative Adversarial Network).","title":"Introduction"},{"location":"projects/animefacegenerator/#anime-face-cropper","text":"In order to limit the scope of the image generation, we need to first crop the anime faces from the images. While using the entire image to generate more fake images is possible, it is a lot more complicated computation wise, and does not transfer well when using the transfer learning technique.","title":"Anime face cropper"},{"location":"projects/animefacegenerator/#image-preprocessor","text":"After obtaining a set of training images, the images then need to be transformed into an appropriate data format so that the GAN model will use. The image preprocessing step will crop the images into square images, ensure that the images are in the RGB colorspace, and make sure the file formats are correct.","title":"Image preprocessor"},{"location":"projects/animefacegenerator/#custom-docker-image-for-gan-training","text":"After the training data is finished with preprocessing, we need to convert it to a format that the GAN will accept. In the custom docker image we will use a script provided by Nvidia called dataset_tool.py that will turn the images into TFRecords, which can be fed into the GAN.","title":"Custom docker image for GAN training"},{"location":"projects/animefacegenerator/#training-on-vastai","text":"In this step, we will then load the docker image with the TFRecords data into VastAI, which allows us to use custom docker images on rental GPU servers. This allows us to use multiple GPUs at once, greatly decreasing the time spent training. After we are done training, the model can be downloaded from the results folder to produce fake images. Sample fake images will also be in the results folder, as well as model checkpoints and sample images at the checkpoints.","title":"Training on VastAI"},{"location":"projects/animefacegenerator/#full-tutorial-on-how-to-use-custom-images-in-stylegan2-ada","text":"A text and video tutorial will be made on how to follow along in using custom images to create fake images using stylegan2-ada. The text tutorial will be in the following pages in the Anime Face Generator directory. Anime Face Cropper - Finished Image Preprocessor - In progress Custom docker image for GAN training - In progress","title":"Full tutorial on how to use custom images in stylegan2-ada"},{"location":"projects/dockerimage/","text":"Link to Github: https://github.com/tonylu0/docker-stylegan2-ada","title":"Custom Docker Image for GAN training"},{"location":"projects/fastaivastai/","text":"FastAI on VastAI Introduction There is a video version of the tutorial on Youtube . This is the text version of the tutorial. It is frequently updated with the latest information and is the fastest method to getting started. This tutorial allows you to utilize VastAI, a cloud gpu rental service, to run FastAI, a great AI kickstarter library. While services like Paperspace and other cloud GPU providers can provide introductory GPUs, a problem arises when more compute is needed. Utilizing powerful hardware on popular cloud providers can prove to be expensive. Therefore, VastAI provides a solution by allowing consumers to rent out their personal GPUs to be used, resulting in a decrease in price. To get started, to go the VastAI website and create an account. After you have created an account, click on the console button at the top right of the website. Setting up the account This brings you to the main page where you can create and rent servers. However, for now, go to the billing page. From here, you can add credit, and the minimum is $5. After this, you can go to the the account page to set up the SSH key. You can get the SSH key through various methods. This guide will show you how to obtain it using a windows machine with SSH installed through Windows subsystem for linux 2. For windows uers with SSH set up, go to C:\\Users\\*Insert Current user*\\.ssh In this folder, you will see 3 files. The first two files are the Private and Public SSH keys, and the third file is the SSH connection history. You will want to select the file with the \"Pub\" extension, which indicates that it is the public SSH key. You can then paste this into the SSH key field on the VastAI website. Be sure to only paste the public key. It is the shorter of the two keys, and has a smaller file size. VastAI will warn you if you paste your private key by mistake. Provisioning a remote GPU server After this, we can finally start up a server! First, go to the create page. I recommend setting the GPU count filter to 1. This allows us to focus only on servers that have 1 GPU. This filter can be adjusted later on when more GPUs can be utilized. Next, click on Edit image & config . Here, you can see various docker images that can be loaded up to the remote servers. Go all the way to the bottom and select the custom container option and enter fastdotai/fastai-course . Next, we will find an appropriate server. For getting used to VastAI, I recommend sorting by price ascending. This allows us to choose the cheapest servers to familiarize the setup with. Later on you can use DLPerf/$/Hour which optimizes for efficiency. For this specific instance, it is important to note that other than the base rental fee of $0.297/hour, there is a storage fee of $0.00694/hour/10gb as well as an internet transfer fee of $0.02/GB. This internet transfer fee can become significant if you are transferring a large amount of data such as downloading training data to the instance or downloading finished models from the instance. This can be avoided by preloading the data to the docker containers by using a custom docker container. There will be a guide on how to do this in the future. Other instances will have different prices for the storage as well as internet transfer. Connecting to the server Once you have chosen a server to rent, you can click on the rent button and then go to the instances page. Here you will be able to see the status of the instance. It usually takes a few minutes for the instance to be set up depending on the internet speed. At the time of writing, you will not be charged for the time it takes to set up the instance and the internet transfer from downloading the instance. You can see the status of the docker container and updates on the bottom after refreshing the page. After the instance is done setting up, you can click on the connect button. This brings up a popup with the command to connect using SSH. Clicking on the command will highlight the entire command, which can then be copied. After copying the SSH command, open up a terminal where SSH is installed. I will show connecting to SSH using Windows Command Prompt. After opening up Command Prompt, right clicking anywhere will paste the contents of the command. After entering the command, it might say connection refused. If it does, just keep on entering the command until it works. When it says if you want to continue, type in yes . Once you have reached this step, type in cd .. to go to the upper folder. Then type cd workspace . After typing ls , we can see the contents of this folder. Then type jupyter notebook --port=8080 --allow-root --no-browser to launch the jupyter notebook. You will see the links to connect to the jupyter notebook in the terminal. After pasting the link in the web browser, you will see your standard jupyter notebook interface. You can now use as any other jupyter notebook. Running programs in the server You can then go into fastbook where the notebooks from the course https://github.com/fastai/fastbook are cloned in. Remember that your current machine may not has as much VRAM as you need so there might be memory errors. I recommend using machines with at least 16GB of VRAM to avoid memory errors. The current instance I am am using has only 11GB of VRAM so the models that I can use are limited. If you see an out of memory error, it is likely because of insufficient VRAM and you need to either lower the batch size or choose a different model. Saving your work After you are done with your work, you need to download it off of the server in order to keep it. Jupyter notebook allows you to select each file individually to download. To download everything, take a look at downloading all files in a path on jupyter notebook or type tar chvfz notebook.tar.gz * in the terminal, which will create a tar file of everything in the current directory. Shutting down the server When you are done saving your work, you can close the jupyter notebook tabs and go to the instances tab on the vastai console. After pressing stop, the charges for running the instance will stop but the charges for storage will continue. It is not recommended to just stop the instance because while the data will be stored on the machine for later use, it is not guaranteed that you will be able to get the same instace later on. Therefore, it is recommended to press the destroy button which will stop the instance as well as delete all the data off of the server, which will stop all charges. After a few seconds of pressing the destroy button, the instance will be deleted and the SSH session will be automatically closed. This is the end of the text tutorial.","title":"FastAI on VastAI"},{"location":"projects/fastaivastai/#fastai-on-vastai","text":"","title":"FastAI on VastAI"},{"location":"projects/fastaivastai/#introduction","text":"There is a video version of the tutorial on Youtube . This is the text version of the tutorial. It is frequently updated with the latest information and is the fastest method to getting started. This tutorial allows you to utilize VastAI, a cloud gpu rental service, to run FastAI, a great AI kickstarter library. While services like Paperspace and other cloud GPU providers can provide introductory GPUs, a problem arises when more compute is needed. Utilizing powerful hardware on popular cloud providers can prove to be expensive. Therefore, VastAI provides a solution by allowing consumers to rent out their personal GPUs to be used, resulting in a decrease in price. To get started, to go the VastAI website and create an account. After you have created an account, click on the console button at the top right of the website.","title":"Introduction"},{"location":"projects/fastaivastai/#setting-up-the-account","text":"This brings you to the main page where you can create and rent servers. However, for now, go to the billing page. From here, you can add credit, and the minimum is $5. After this, you can go to the the account page to set up the SSH key. You can get the SSH key through various methods. This guide will show you how to obtain it using a windows machine with SSH installed through Windows subsystem for linux 2. For windows uers with SSH set up, go to C:\\Users\\*Insert Current user*\\.ssh In this folder, you will see 3 files. The first two files are the Private and Public SSH keys, and the third file is the SSH connection history. You will want to select the file with the \"Pub\" extension, which indicates that it is the public SSH key. You can then paste this into the SSH key field on the VastAI website. Be sure to only paste the public key. It is the shorter of the two keys, and has a smaller file size. VastAI will warn you if you paste your private key by mistake.","title":"Setting up the account"},{"location":"projects/fastaivastai/#provisioning-a-remote-gpu-server","text":"After this, we can finally start up a server! First, go to the create page. I recommend setting the GPU count filter to 1. This allows us to focus only on servers that have 1 GPU. This filter can be adjusted later on when more GPUs can be utilized. Next, click on Edit image & config . Here, you can see various docker images that can be loaded up to the remote servers. Go all the way to the bottom and select the custom container option and enter fastdotai/fastai-course . Next, we will find an appropriate server. For getting used to VastAI, I recommend sorting by price ascending. This allows us to choose the cheapest servers to familiarize the setup with. Later on you can use DLPerf/$/Hour which optimizes for efficiency. For this specific instance, it is important to note that other than the base rental fee of $0.297/hour, there is a storage fee of $0.00694/hour/10gb as well as an internet transfer fee of $0.02/GB. This internet transfer fee can become significant if you are transferring a large amount of data such as downloading training data to the instance or downloading finished models from the instance. This can be avoided by preloading the data to the docker containers by using a custom docker container. There will be a guide on how to do this in the future. Other instances will have different prices for the storage as well as internet transfer.","title":"Provisioning a remote GPU server"},{"location":"projects/fastaivastai/#connecting-to-the-server","text":"Once you have chosen a server to rent, you can click on the rent button and then go to the instances page. Here you will be able to see the status of the instance. It usually takes a few minutes for the instance to be set up depending on the internet speed. At the time of writing, you will not be charged for the time it takes to set up the instance and the internet transfer from downloading the instance. You can see the status of the docker container and updates on the bottom after refreshing the page. After the instance is done setting up, you can click on the connect button. This brings up a popup with the command to connect using SSH. Clicking on the command will highlight the entire command, which can then be copied. After copying the SSH command, open up a terminal where SSH is installed. I will show connecting to SSH using Windows Command Prompt. After opening up Command Prompt, right clicking anywhere will paste the contents of the command. After entering the command, it might say connection refused. If it does, just keep on entering the command until it works. When it says if you want to continue, type in yes . Once you have reached this step, type in cd .. to go to the upper folder. Then type cd workspace . After typing ls , we can see the contents of this folder. Then type jupyter notebook --port=8080 --allow-root --no-browser to launch the jupyter notebook. You will see the links to connect to the jupyter notebook in the terminal. After pasting the link in the web browser, you will see your standard jupyter notebook interface. You can now use as any other jupyter notebook.","title":"Connecting to the server"},{"location":"projects/fastaivastai/#running-programs-in-the-server","text":"You can then go into fastbook where the notebooks from the course https://github.com/fastai/fastbook are cloned in. Remember that your current machine may not has as much VRAM as you need so there might be memory errors. I recommend using machines with at least 16GB of VRAM to avoid memory errors. The current instance I am am using has only 11GB of VRAM so the models that I can use are limited. If you see an out of memory error, it is likely because of insufficient VRAM and you need to either lower the batch size or choose a different model.","title":"Running programs in the server"},{"location":"projects/fastaivastai/#saving-your-work","text":"After you are done with your work, you need to download it off of the server in order to keep it. Jupyter notebook allows you to select each file individually to download. To download everything, take a look at downloading all files in a path on jupyter notebook or type tar chvfz notebook.tar.gz * in the terminal, which will create a tar file of everything in the current directory.","title":"Saving your work"},{"location":"projects/fastaivastai/#shutting-down-the-server","text":"When you are done saving your work, you can close the jupyter notebook tabs and go to the instances tab on the vastai console. After pressing stop, the charges for running the instance will stop but the charges for storage will continue. It is not recommended to just stop the instance because while the data will be stored on the machine for later use, it is not guaranteed that you will be able to get the same instace later on. Therefore, it is recommended to press the destroy button which will stop the instance as well as delete all the data off of the server, which will stop all charges. After a few seconds of pressing the destroy button, the instance will be deleted and the SSH session will be automatically closed. This is the end of the text tutorial.","title":"Shutting down the server"},{"location":"projects/imagepreprocess/","text":"","title":"Image Preprocessor"}]}